{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "The most common way to do Bayesian Logistic Regression is to use the Laplace Approximation.\n",
    "\n",
    "## The Model\n",
    "\n",
    "The model is the same as Linear Regression, except the output is passed through a Logistic Sigmoid to give output that is on [0,1].\n",
    "\n",
    "$P(\\mathbf{w}) = \\mathcal{N}(\\mathbf{0}, \\alpha^{-1}\\mathbf{I})$\n",
    "\n",
    "$P(\\mathbf{y} \\mid \\mathbf{X}, \\mathbf{w} ) = \\sigma(\\mathcal{N}(\\mathbf{Xw}, \\beta^{-1}\\mathbf{I}))$\n",
    "\n",
    "## No More Conjugacy\n",
    "\n",
    "This model is not conjugate - what we typically do is is approximate the posterior with a Normal distribution. This is a useful approximation, as we then have a conjugate posterior-likelihood pair. This means if we want a predictive distribution, everything is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.w = torch.nn.Linear(in_features, out_features)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.bce = torch.nn.BCELoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.w(x))\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        y_hat = self.forward(x)\n",
    "        l2 = torch.matmul(self.w.weight, self.w.weight.transpose(0,1)).sum()+self.w.bias**2\n",
    "        return self.bce(y_hat, y) + l2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LogisticRegression(10,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
